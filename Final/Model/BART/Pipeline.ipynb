{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T00:52:16.241430Z",
     "iopub.status.busy": "2025-04-07T00:52:16.241080Z",
     "iopub.status.idle": "2025-04-07T00:52:18.370427Z",
     "shell.execute_reply": "2025-04-07T00:52:18.369426Z",
     "shell.execute_reply.started": "2025-04-07T00:52:16.241397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clan-dataset/CLAN_data.csv\n",
      "/kaggle/input/clan-dataset/2_Cleaning_Paper.ipynb\n",
      "/kaggle/input/clan-dataset/CLAN_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T01:08:03.607772Z",
     "iopub.status.busy": "2025-04-07T01:08:03.607383Z",
     "iopub.status.idle": "2025-04-07T01:08:09.529114Z",
     "shell.execute_reply": "2025-04-07T01:08:09.528253Z",
     "shell.execute_reply.started": "2025-04-07T01:08:03.607713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: bleu in /usr/local/lib/python3.10/dist-packages (0.3)\n",
      "Requirement already satisfied: rogue in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.5)\n",
      "Requirement already satisfied: efficiency in /usr/local/lib/python3.10/dist-packages (from bleu) (2.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=e073351eb93d771f03ba52d5735ede0f5f6c41286a960f1a2864705820e929ed\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: portalocker, sacrebleu, rouge-score\n",
      "Successfully installed portalocker-3.1.1 rouge-score-0.1.2 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch scikit-learn transformers datasets evaluate bert-score tqdm bleu rogue rouge-score sacrebleu bert-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T01:12:35.826567Z",
     "iopub.status.busy": "2025-04-07T01:12:35.826231Z",
     "iopub.status.idle": "2025-04-07T01:21:47.256975Z",
     "shell.execute_reply": "2025-04-07T01:21:47.256171Z",
     "shell.execute_reply.started": "2025-04-07T01:12:35.826543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf73a4b00ae4688a38027f0d805097a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb91f0e5ce44c7894edbe82c4300900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae73a89aaec4fbd885dad1b1ef7a19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 200/200 [01:07<00:00,  2.96it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51141acc28da48bf92a23feef48fefa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dbd36ab37f4d5db29e3e5b8600cd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dcbd97283d4c1ea1edaacb5e695e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a6f56a3ecf4f82a4f155e0ca46b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454ebc0443504f8cb64092479bb239a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c1fbd8f2a3469db98ba872ff019693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "Train Loss : 2.9860\n",
      "Val Loss   : 2.6923\n",
      "ROUGE-L    : 0.3349\n",
      "BLEU-4     : 0.2014\n",
      "BERTScore  : 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 200/200 [01:07<00:00,  2.98it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "Train Loss : 2.3344\n",
      "Val Loss   : 2.6490\n",
      "ROUGE-L    : 0.3410\n",
      "BLEU-4     : 0.2143\n",
      "BERTScore  : 0.8820\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 200/200 [01:06<00:00,  2.99it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "Train Loss : 1.9392\n",
      "Val Loss   : 2.6619\n",
      "ROUGE-L    : 0.3484\n",
      "BLEU-4     : 0.2210\n",
      "BERTScore  : 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 200/200 [01:06<00:00,  3.00it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "Train Loss : 1.5860\n",
      "Val Loss   : 2.7456\n",
      "ROUGE-L    : 0.3412\n",
      "BLEU-4     : 0.2142\n",
      "BERTScore  : 0.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 200/200 [01:06<00:00,  3.01it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "Train Loss : 1.4011\n",
      "Val Loss   : 2.8829\n",
      "ROUGE-L    : 0.3493\n",
      "BLEU-4     : 0.2231\n",
      "BERTScore  : 0.8846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv(\"/kaggle/input/clan-dataset/CLAN_data_cleaned.csv\")\n",
    "df = df[[\"Social Media Post\", \"Normalized Claim\"]].dropna()\n",
    "\n",
    "# Split the dataset: 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Load BART tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Social Media Post\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples[\"Normalized Claim\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    labels = targets[\"input_ids\"]\n",
    "    labels = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in labels\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model and device\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            # Generate predictions\n",
    "            generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
    "\n",
    "            # Replace -100 in labels before decoding\n",
    "            labels = torch.where(labels != -100, labels, torch.tensor(tokenizer.pad_token_id).to(labels.device))\n",
    "\n",
    "            # Decode\n",
    "            decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_labels)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    rouge_result = rouge.compute(predictions=predictions, references=references, rouge_types=[\"rougeL\"])\n",
    "    bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "    bertscore_result = score(predictions, references, lang=\"en\", verbose=False)\n",
    "    bertscore_avg = bertscore_result[2].mean().item()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss   : {avg_val_loss:.4f}\")\n",
    "    print(f\"ROUGE-L    : {rouge_result['rougeL']:.4f}\")\n",
    "    print(f\"BLEU-4     : {bleu_result['bleu']:.4f}\")\n",
    "    print(f\"BERTScore  : {bertscore_avg:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        model.save_pretrained(\"/kaggle/working//bart_model_output/final\")\n",
    "        tokenizer.save_pretrained(\"/kaggle/working//bart_model_output/final\")\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "# Save the test split for inference\n",
    "test_df.to_csv(\"/kaggle/working/test_data_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T01:58:42.974993Z",
     "iopub.status.busy": "2025-04-07T01:58:42.974618Z",
     "iopub.status.idle": "2025-04-07T01:58:43.009298Z",
     "shell.execute_reply": "2025-04-07T01:58:43.008213Z",
     "shell.execute_reply.started": "2025-04-07T01:58:42.974967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f135c27176fc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluating Test Set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_ids'"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Generate predictions\n",
    "        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
    "\n",
    "        # Replace -100 in labels with pad_token_id before decoding\n",
    "        labels = torch.where(labels != -100, labels, torch.tensor(tokenizer.pad_token_id).to(labels.device))\n",
    "\n",
    "        # Decode predictions and references\n",
    "        decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        test_predictions.extend(decoded_preds)\n",
    "        test_references.extend(decoded_labels)\n",
    "\n",
    "# Compute metrics\n",
    "rouge_result = rouge.compute(predictions=test_predictions, references=test_references, rouge_types=[\"rougeL\"])\n",
    "bleu_result = bleu.compute(predictions=test_predictions, references=test_references)\n",
    "bertscore_result = score(test_predictions, test_references, lang=\"en\", verbose=False)\n",
    "bertscore_avg = bertscore_result[2].mean().item()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n✅ Test Set Metrics:\")\n",
    "print(f\"ROUGE-L   : {rouge_result['rougeL']:.4f}\")\n",
    "print(f\"BLEU-4    : {bleu_result['bleu']:.4f}\")\n",
    "print(f\"BERTScore : {bertscore_avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:06:17.041332Z",
     "iopub.status.busy": "2025-04-07T02:06:17.041048Z",
     "iopub.status.idle": "2025-04-07T02:06:31.465632Z",
     "shell.execute_reply": "2025-04-07T02:06:31.464655Z",
     "shell.execute_reply.started": "2025-04-07T02:06:17.041308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8405dead886f4800b877b76700b708d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "ROUGE-L : 0.1981\n",
      "BLEU-4  : 0.0000\n",
      "BERTScore (F1): 0.8605\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from bert_score import score\n",
    "\n",
    "# Load saved model and tokenizer\n",
    "model_path = \"/kaggle/working/bart_model_output/final\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"/kaggle/input/testdataclan/test_data_cleaned.csv\")\n",
    "test_df = test_df[[\"Social Media Post\", \"Normalized Claim\"]].dropna()\n",
    "\n",
    "# Tokenize test data\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Social Media Post\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples[\"Normalized Claim\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    labels = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in targets[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "        \"label_ids\": targets[\"input_ids\"]  # Keep original label IDs for decoding\n",
    "    }\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"label_ids\"])\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoader for test set\n",
    "test_loader = DataLoader(tokenized_test_dataset, batch_size=1)\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# Inference loop\n",
    "for batch in test_loader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(batch[\"label_ids\"], skip_special_tokens=True)\n",
    "\n",
    "    predictions.extend(decoded_preds)\n",
    "    references.extend(decoded_labels)\n",
    "\n",
    "# Evaluation\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references, rouge_types=[\"rougeL\"])\n",
    "bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "bertscore_result = score(predictions, references, lang=\"en\", verbose=False)\n",
    "bertscore_avg = bertscore_result[2].mean().item()\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(f\"ROUGE-L : {rouge_result['rougeL']:.4f}\")\n",
    "print(f\"BLEU-4  : {bleu_result['bleu']:.4f}\")\n",
    "print(f\"BERTScore (F1): {bertscore_avg:.4f}\")\n",
    "\n",
    "# Optional: Save predictions to CSV\n",
    "output_df = pd.DataFrame({\n",
    "    \"Original Post\": test_df[\"Social Media Post\"],\n",
    "    \"Reference Claim\": references,\n",
    "    \"Predicted Claim\": predictions\n",
    "})\n",
    "output_df.to_csv(\"/kaggle/working/bart_test_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:07:25.212498Z",
     "iopub.status.busy": "2025-04-07T02:07:25.212157Z",
     "iopub.status.idle": "2025-04-07T02:09:08.245264Z",
     "shell.execute_reply": "2025-04-07T02:09:08.244256Z",
     "shell.execute_reply.started": "2025-04-07T02:07:25.212475Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff1ee2ef0a54a9798df5231d27cfeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating External Test Set: 100%|██████████| 471/471 [01:35<00:00,  4.95it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[External Test CSV Evaluation]\n",
      "ROUGE-L    : 0.3694\n",
      "BLEU-4     : 0.2470\n",
      "BERTScore  : 0.8890\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load external test CSV\n",
    "external_df = pd.read_csv(\"/kaggle/input/complete/CLAN_data_cleaned_test.csv\")\n",
    "external_df = external_df[[\"Social Media Post\", \"Normalized Claim\"]].dropna()\n",
    "\n",
    "# Tokenize external test set\n",
    "external_dataset = Dataset.from_pandas(external_df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Social Media Post\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples[\"Normalized Claim\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    labels = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in targets[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "        \"label_ids\": targets[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "# Tokenize and set format\n",
    "external_dataset = external_dataset.map(tokenize_function, batched=True)\n",
    "external_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"label_ids\"])\n",
    "\n",
    "external_loader = DataLoader(external_dataset, batch_size=1)\n",
    "\n",
    "# Inference on external dataset\n",
    "external_preds = []\n",
    "external_refs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(external_loader, desc=\"Evaluating External Test Set\"):\n",
    "        input_ids = batch[\"input_ids\"].to(model.device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(batch[\"label_ids\"], skip_special_tokens=True)\n",
    "\n",
    "        external_preds.extend(decoded_preds)\n",
    "        external_refs.extend(decoded_labels)\n",
    "\n",
    "# Compute metrics\n",
    "rouge_result = rouge.compute(predictions=external_preds, references=external_refs, rouge_types=[\"rougeL\"])\n",
    "bleu_result = bleu.compute(predictions=external_preds, references=external_refs)\n",
    "bertscore_result = score(external_preds, external_refs, lang=\"en\", verbose=False)\n",
    "\n",
    "print(\"\\n[External Test CSV Evaluation]\")\n",
    "print(f\"ROUGE-L    : {rouge_result['rougeL']:.4f}\")\n",
    "print(f\"BLEU-4     : {bleu_result['bleu']:.4f}\")\n",
    "print(f\"BERTScore  : {bertscore_result[2].mean().item():.4f}\")\n",
    "\n",
    "# Save predictions (optional)\n",
    "output_df = pd.DataFrame({\n",
    "    \"Original Post\": external_df[\"Social Media Post\"],\n",
    "    \"Reference Claim\": external_refs,\n",
    "    \"Predicted Claim\": external_preds\n",
    "})\n",
    "output_df.to_csv(\"/kaggle/working/bart_external_test_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7059262,
     "sourceId": 11289839,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7068809,
     "sourceId": 11303031,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7068913,
     "sourceId": 11303171,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
