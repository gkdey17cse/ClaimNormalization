{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd84c84",
   "metadata": {},
   "source": [
    "## Task 2 : Claim Normalization using BART (Base) & T5 (small)\n",
    "### By Gour Krishna Dey | MT24035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fe7787-3100-4daf-ac7f-c8d7dfdf8ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:34:42.405161Z",
     "iopub.status.busy": "2025-04-08T22:34:42.404768Z",
     "iopub.status.idle": "2025-04-08T22:34:42.812005Z",
     "shell.execute_reply": "2025-04-08T22:34:42.811088Z",
     "shell.execute_reply.started": "2025-04-08T22:34:42.405133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e304571-087d-4edc-a240-a42d96ec7469",
   "metadata": {},
   "source": [
    "# Pretrained Model (BART-base & T5-small)\n",
    "\n",
    "If you use kaggle then unzip the existing model whihc will be import for testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d851bc2-6fdb-4a2d-922a-41f2a65f5d34",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!unzip -q \"/kaggle/input/your-dataset-name/t5_clan_model.zip\" -d \"/kaggle/working/Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ed4b1-5a3d-4293-b3b5-47af81dffb2d",
   "metadata": {},
   "source": [
    "# All Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e59c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:34:48.351319Z",
     "iopub.status.busy": "2025-04-08T22:34:48.350876Z",
     "iopub.status.idle": "2025-04-08T22:35:35.639150Z",
     "shell.execute_reply": "2025-04-08T22:35:35.637736Z",
     "shell.execute_reply.started": "2025-04-08T22:34:48.351288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets sentencepiece evaluate bert-score rouge-score matplotlib nltk sacrebleu contractions\n",
    "!pip install --upgrade transformers\n",
    "!pip install transformers datasets evaluate rouge-score sacrebleu bert-score --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df59547-69c4-4bcb-bd0b-fd31e089d52b",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "This Code will preprocessed given noise input.csv file and make an cleaned .csv file which can be use for further inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec04500",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re  # Regular expressions\n",
    "import string\n",
    "import contractions  # contraxtions library to expand contractions\n",
    "\n",
    "\n",
    "def text_cleaner(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = contractions.fix(text)  # Expand Contraction : ex - \"can't\" -> \"cannot\"\n",
    "\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Twitter handles remove\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # URLs remove\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # HTML tags remove\n",
    "\n",
    "    text = (\n",
    "        text.replace('\"', \"\").replace(\"“\", \"\").replace(\"”\", \"\")\n",
    "    )  # Remove double quotes\n",
    "\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)  # Remover Hashtags but keep the original word\n",
    "\n",
    "    # Remove newlines, tabs, extra whitespace\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "\n",
    "    # Remove non-informative punctuation ( Ex - \"@#$%^&*()[]{};:'<>?/\" )\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation.replace('.', '').replace(',', '').replace('!', '').replace('?', ''))}]\",\n",
    "        \"\",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def raw_data_preprocesser(input_path, output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    df = df[[\"PID\", \"Social Media Post\", \"Normalized Claim\"]]\n",
    "\n",
    "    df.dropna(\n",
    "        subset=[\"Social Media Post\", \"Normalized Claim\"], inplace=True\n",
    "    )  # Drop rows with NaN in either column\n",
    "\n",
    "    df[\"Social Media Post\"] = df[\"Social Media Post\"].apply(\n",
    "        text_cleaner\n",
    "    )  # Clean the \"Social Media Post\" column\n",
    "    df[\"Normalized Claim\"] = df[\"Normalized Claim\"].apply(\n",
    "        text_cleaner\n",
    "    )  # Clean the \"Normalized Claim\" column\n",
    "\n",
    "    df = df[\n",
    "        (df[\"Social Media Post\"].str.strip() != \"\")\n",
    "        & (df[\"Normalized Claim\"].str.strip() != \"\")\n",
    "    ]  # Drop empty strings after cleaning\n",
    "\n",
    "    df.drop_duplicates(subset=[\"Social Media Post\", \"Normalized Claim\"], inplace=True)\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "input_raw_csv = \"/home/slimsense/GourKrishna/NLP3/Data/Test_data_2.csv\"  ## Modify this variable with ACTUAL RAW CSV data\n",
    "output_cleaned_csv = \"/home/slimsense/GourKrishna/NLP3/Data/Test_data2_Processed.csv\"  ## Modify this variable with ACTUAL CLEANED CSV data\n",
    "cleaned_df = raw_data_preprocesser(\n",
    "    input_raw_csv, output_cleaned_csv\n",
    ")  ## convert input csv -> output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fba65e-6e80-4ea1-a4aa-3315985c98c8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For testing\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/kaggle/working/test_data_cleaned.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c80c30",
   "metadata": {},
   "source": [
    "# Code to Train BART-BASE Piepeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5256c8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch  # PyTorch library for tensor operations\n",
    "from transformers import (\n",
    "    BartTokenizer,\n",
    "    BartForConditionalGeneration,\n",
    ")  # BART tokenizer and model\n",
    "from torch.utils.data import DataLoader  # DataLoader for batching and shuffling data\n",
    "from torch.optim import AdamW  # AdamW optimizer for training\n",
    "from datasets import Dataset  # Hugging Face Datasets library\n",
    "from sklearn.model_selection import train_test_split  # Train-test split\n",
    "import evaluate  # Evaluation library for NLP tasks\n",
    "from bert_score import score  # bert-score library for evaluation\n",
    "from tqdm import tqdm  # Progress bar library to see progress\n",
    "\n",
    "\n",
    "# Load and pre - proces the dataset\n",
    "df = pd.read_csv(\n",
    "    \"/home/slimsense/GourKrishna/NLP3/Data/CLAN_data_cleaned.csv\"\n",
    ")  ## UPDATE THIS PATH WITH THE ACTUAL PATH of the TRAININD CSV FILE\n",
    "df = df[[\"Social Media Post\", \"Normalized Claim\"]].dropna()\n",
    "\n",
    "# Split the dataset into : 70% train, 15% validation, 15% test as mentioned in the question\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Load BART tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Tokenization function\n",
    "\"\"\"\n",
    "From - \n",
    "{\n",
    "  'Social Media Post': 'Joe Biden is great',\n",
    "  'Normalized Claim': 'Biden is amazing'\n",
    "}\n",
    "To - {\n",
    "  'input_ids': [0, 314, 567, 17, 1024, 2, 1, 1, 1],\n",
    "  'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "  'labels': [0, 201, 421, 90, 2, -100, -100, -100, -100],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"Social Media Post\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        examples[\"Normalized Claim\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    labels = targets[\"input_ids\"]\n",
    "    labels = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in labels\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model and device ( will use GPU if available and preferrable for training & testing both)\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/bart-base\"\n",
    ")  # Model for conditional generation (ex- text summarization)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Use ADAM Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            # Generate predictions\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, max_length=64\n",
    "            )  # Here actual predictions are generated based on the input_ids and attention_mask\n",
    "\n",
    "            # Will replace -100 in labels before starting decoding\n",
    "            labels = torch.where(\n",
    "                labels != -100,\n",
    "                labels,\n",
    "                torch.tensor(tokenizer.pad_token_id).to(labels.device),\n",
    "            )\n",
    "\n",
    "            # Decode predictions and labels\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_ids, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(\n",
    "                labels, skip_special_tokens=True\n",
    "            )  # skip_special_tokens ex - <pad>, <s>, </s>\n",
    "\n",
    "            predictions.extend(\n",
    "                decoded_preds\n",
    "            )  # Append the decoded predictions to the list\n",
    "            references.extend(decoded_labels)  # Append the decoded labels to the list\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    rouge_result = rouge.compute(\n",
    "        predictions=predictions, references=references, rouge_types=[\"rougeL\"]\n",
    "    )  # ROUGE-L score computation\n",
    "    bleu_result = bleu.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )  # BLEU-4 score computation\n",
    "    bertscore_result = score(\n",
    "        predictions, references, lang=\"en\", verbose=False\n",
    "    )  # BERTScore computation\n",
    "    bertscore_avg = bertscore_result[2].mean().item()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")  # Print the summary of the epoch\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss   : {avg_val_loss:.4f}\")\n",
    "    print(f\"ROUGE-L    : {rouge_result['rougeL']:.4f}\")\n",
    "    print(f\"BLEU-4     : {bleu_result['bleu']:.4f}\")\n",
    "    print(f\"BERTScore  : {bertscore_avg:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:  # Save the best model based on validation loss\n",
    "        best_val_loss = avg_val_loss\n",
    "        model.save_pretrained(\n",
    "            \"/home/slimsense/GourKrishna/NLP3/Model/bart_model_output/final\"\n",
    "        )\n",
    "        tokenizer.save_pretrained(\n",
    "            \"/home/slimsense/GourKrishna/NLP3/Model/bart_model_output/final\"\n",
    "        )\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "# Save the test split for inference\n",
    "test_df.to_csv(\n",
    "    \"/home/slimsense/GourKrishna/NLP3/Data/test_data_cleaned.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5608b6",
   "metadata": {},
   "source": [
    "# INFERENCE PIPELINE (BART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0076f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:37:30.659249Z",
     "iopub.status.busy": "2025-04-08T22:37:30.658807Z",
     "iopub.status.idle": "2025-04-08T22:38:02.068630Z",
     "shell.execute_reply": "2025-04-08T22:38:02.067507Z",
     "shell.execute_reply.started": "2025-04-08T22:37:30.659218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\venvClaimNormalization\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 312.66 examples/s]\n",
      "Using the latest cached version of the module from C:\\Users\\Gour krishna Dey\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bleu\\9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Wed Jun  4 10:47:23 2025) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "ROUGE-L : 0.2407\n",
      "BLEU-4  : 0.0592\n",
      "BERTScore (F1): 0.8721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Pandas library for data manipuletion\n",
    "import torch  # PyTorch library for tensor operations\n",
    "from transformers import (\n",
    "    BartTokenizer,\n",
    "    BartForConditionalGeneration,\n",
    ")  # BART tokenizar and model\n",
    "from datasets import Dataset  # Hugging-Face Datasets library\n",
    "from torch.utils.data import DataLoader  # DataLoader for batching and shufling data\n",
    "import evaluate  # evalution library for NLP tasks\n",
    "from bert_score import score  # bert-score library\n",
    "\n",
    "# Load priorly saved model and tokenizer\n",
    "# model_path = \"/Model/BART/bart_model_output/final\"  # CHNAGE WITH SAVE MODELS PATH\n",
    "model_path = r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Model\\BART\\bart_model_output\\final\"\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Load test data for inference\n",
    "test_df = pd.read_csv(\n",
    "    r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Data\\Test_data.csv\"\n",
    ")  # CHANGE WITH PROCESSED TEST DATA's PATH (File upon which we need to test)\n",
    "test_df = test_df[[\"Social Media Post\", \"Normalized Claim\"]].dropna()\n",
    "\n",
    "# Tokenize test data\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples[\"Social Media Post\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )  # define the input sequence\n",
    "    targets = tokenizer(\n",
    "        examples[\"Normalized Claim\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )  # define the target sequence\n",
    "\n",
    "    labels = [  # Will replace -100 with the pad token id for the labels\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n",
    "        for label_seq in targets[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    return {  # return the tokenized inputs and labels\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "        \"label_ids\": targets[\"input_ids\"],  # Keep original label IDs for decoding\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"label_ids\"]\n",
    ")  # set the format\n",
    "\n",
    "# Move model to device (GPU is preferred)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoader for test set\n",
    "test_loader = DataLoader(tokenized_test_dataset, batch_size=1)\n",
    "\n",
    "predictions = []  # List to store the predictions\n",
    "references = []  # List to store the references (actual labels)\n",
    "\n",
    "# Inference loop\n",
    "for batch in test_loader:  # Iterate over the test DataLoader\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(\n",
    "        outputs, skip_special_tokens=True\n",
    "    )  # Decode the generated predictions\n",
    "    decoded_labels = tokenizer.batch_decode(\n",
    "        batch[\"label_ids\"], skip_special_tokens=True\n",
    "    )  # Decode the original labels\n",
    "\n",
    "    predictions.extend(decoded_preds)  # Predictions are appended to the lis\n",
    "    references.extend(decoded_labels)  # References are appended to the list\n",
    "\n",
    "# Evaluation\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "rouge_result = rouge.compute(\n",
    "    predictions=predictions, references=references, rouge_types=[\"rougeL\"]\n",
    ")  # ROUGE-L score computation\n",
    "bleu_result = bleu.compute(\n",
    "    predictions=predictions, references=references\n",
    ")  # BLEU-4 score computation\n",
    "bertscore_result = score(\n",
    "    predictions, references, lang=\"en\", verbose=False\n",
    ")  # BERTScore computation\n",
    "bertscore_avg = bertscore_result[2].mean().item()\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")  # Print the evaluation results\n",
    "print(f\"ROUGE-L : {rouge_result['rougeL']:.4f}\")\n",
    "print(f\"BLEU-4  : {bleu_result['bleu']:.4f}\")\n",
    "print(f\"BERTScore (F1): {bertscore_avg:.4f}\")\n",
    "\n",
    "output_df = pd.DataFrame(\n",
    "    {  # DataFrame to store the results\n",
    "        \"Original Post\": test_df[\"Social Media Post\"],\n",
    "        \"Reference Claim\": references,\n",
    "        \"Predicted Claim\": predictions,\n",
    "    }\n",
    ")\n",
    "output_df.to_csv(\n",
    "    r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Data\\bart_test_predictions.csv\", index=False\n",
    ")  # WILL SAVE THE predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec07fa75",
   "metadata": {},
   "source": [
    "# Code to train T5-Small Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d59b2-5575-4ed9-b1bf-6bbb139d167d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install transformers==4.51.1 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875106d0-0393-4ff3-985d-54efc0253699",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f1bfc",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Data manipulation and analysis\n",
    "import torch  # PyTorch library for tensor opn\n",
    "from datasets import Dataset  # Hugging Face Datasets library\n",
    "from transformers import (  # Tokenizer and model for T5\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from nltk.translate.bleu_score import (\n",
    "    sentence_bleu,\n",
    "    SmoothingFunction,\n",
    ")  # BLEU score computation\n",
    "from rouge_score import rouge_scorer  # ROUGE score computation\n",
    "from bert_score import score as bertscore  # BERTScore computation\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "print(\"TrainingArguments from:\", TrainingArguments.__module__)\n",
    "\n",
    "\n",
    "# Check for GPU (Prefarable)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA not available.\")\n",
    "\n",
    "# Data Loading and Preprocessing\n",
    "df = pd.read_csv(\"/home/slimsense/GourKrishna/NLP3/Data/CLAN_data_cleaned.csv\")\n",
    "df = df[[\"Social Media Post\", \"Normalized Claim\"]].dropna().drop_duplicates()\n",
    "df = df[\n",
    "    (df[\"Social Media Post\"].str.strip() != \"\")\n",
    "    & (df[\"Normalized Claim\"].str.strip() != \"\")\n",
    "]  # Drop empty strings after cleaning\n",
    "\n",
    "# Split the dataset into train, validation, and test sets (70-15-15 as mentioned in the question)\n",
    "train_df = df.sample(frac=0.7, random_state=42)  # 70% for training\n",
    "temp_df = df.drop(train_df.index)\n",
    "val_df = temp_df.sample(frac=0.5, random_state=42)  # 15% for validation\n",
    "test_df = temp_df.drop(val_df.index)\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_ds = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "# Load T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(\n",
    "    device\n",
    ")  # Load T5 model\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(example):  # Preprocess the dataset\n",
    "    input_enc = tokenizer(\n",
    "        \"normalize: \" + example[\"Social Media Post\"],  # Add prefix to the input\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    target_enc = tokenizer(  # Tokenize the target\n",
    "        example[\"Normalized Claim\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_enc[\"labels\"] = [  # Set the labels for the target\n",
    "        (label if label != tokenizer.pad_token_id else -100)\n",
    "        for label in target_enc[\"input_ids\"]\n",
    "    ]\n",
    "    return input_enc  # Return the tokenized input and labels togethr\n",
    "\n",
    "\n",
    "# Apply preprocessing to the datasets\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_ds.set_format(type=\"torch\")\n",
    "val_ds.set_format(type=\"torch\")\n",
    "test_ds.set_format(type=\"torch\")\n",
    "\n",
    "\n",
    "# Data Collator\n",
    "class EvalMetricsCallback(TrainerCallback):\n",
    "    def on_evaluate(\n",
    "        self, args, state, control, **kwargs\n",
    "    ):  # Callback to compute evaluation metrics\n",
    "        model.eval()\n",
    "        predictions, references = [], []\n",
    "\n",
    "        for i in range(min(100, len(val_ds))):\n",
    "            sample = val_ds[i]  # Get the sample from the validation dataset\n",
    "            input_ids = (\n",
    "                sample[\"input_ids\"].unsqueeze(0).to(device)\n",
    "            )  # Add batch dimension\n",
    "            attn_mask = (\n",
    "                sample[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "            )  # Move attention mask\n",
    "            labels = sample[\"labels\"]  # Get the labels\n",
    "\n",
    "            with torch.no_grad():  # Disable gradient calculation\n",
    "                gen_ids = model.generate(  # Generate predictions\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attn_mask,\n",
    "                    max_length=128,\n",
    "                    num_beams=4,\n",
    "                )\n",
    "\n",
    "            pred = tokenizer.decode(\n",
    "                gen_ids[0], skip_special_tokens=True\n",
    "            )  # Decode the generated IDs\n",
    "            ref = tokenizer.decode(\n",
    "                [t for t in labels if t != -100], skip_special_tokens=True\n",
    "            )  # Decode the labels\n",
    "\n",
    "            predictions.append(pred)  # Append the decoded predictions\n",
    "            references.append(ref)  # Append the decoded references\n",
    "\n",
    "        # Compute BLEU-4\n",
    "        bleu_scores = [\n",
    "            sentence_bleu(\n",
    "                [ref.split()],\n",
    "                pred.split(),\n",
    "                smoothing_function=SmoothingFunction().method1,\n",
    "            )\n",
    "            for pred, ref in zip(predictions, references)\n",
    "        ]\n",
    "        print(f\"\\nEpoch {int(state.epoch)} Metrics:\")\n",
    "        print(\"BLEU-4    :\", round(sum(bleu_scores) / len(bleu_scores), 4))\n",
    "\n",
    "        # ROUGE-L\n",
    "        rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "        rouge_scores = [\n",
    "            rouge.score(r, p)[\"rougeL\"].fmeasure\n",
    "            for p, r in zip(predictions, references)\n",
    "        ]\n",
    "        print(\"ROUGE-L   :\", round(sum(rouge_scores) / len(rouge_scores), 4))\n",
    "\n",
    "        # BERTScore\n",
    "        P, R, F1 = bertscore(predictions, references, lang=\"en\", verbose=False)\n",
    "        print(\"BERTScore :\", round(F1.mean().item(), 4))\n",
    "\n",
    "\n",
    "# Training Arguments define\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/home/slimsense/GourKrishna/NLP3/Model/T5/t5_clan\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=5,\n",
    "    do_eval=True,\n",
    "    do_train=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)  # Data collator for T5\n",
    "\n",
    "trainer = Trainer(  # Trainer for T5\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EvalMetricsCallback()],\n",
    ")\n",
    "\n",
    "trainer.train()  # Train the model\n",
    "trainer.save_model(\"/home/slimsense/GourKrishna/NLP3/Model/T5/t5_clan\")\n",
    "tokenizer.save_pretrained(\"/home/slimsense/GourKrishna/NLP3/Model/T5/t5_clan\")\n",
    "\n",
    "# Inference\n",
    "sample = test_ds[0]\n",
    "input_ids = sample[\"input_ids\"].unsqueeze(0).to(device)\n",
    "attn_mask = sample[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attn_mask, max_length=128\n",
    "    )\n",
    "\n",
    "print(\"\\nPrediction Example :\")  # Print the example for debug\n",
    "print(\"Input     :\", tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True))\n",
    "print(\"Prediction:\", tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(\n",
    "    \"Reference :\",\n",
    "    tokenizer.decode(\n",
    "        [i for i in sample[\"labels\"] if i != -100], skip_special_tokens=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ecd7f9",
   "metadata": {},
   "source": [
    "# INFERENCE PIPELINE (T5-Small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3b646d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T22:38:52.101074Z",
     "iopub.status.busy": "2025-04-08T22:38:52.100660Z",
     "iopub.status.idle": "2025-04-08T22:42:46.530070Z",
     "shell.execute_reply": "2025-04-08T22:42:46.528862Z",
     "shell.execute_reply.started": "2025-04-08T22:38:52.101043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\venvClaimNormalization\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 20/20 [00:26<00:00,  1.34s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "BLEU-4    : 0.0442\n",
      "ROUGE-L   : 0.2804\n",
      "BERTScore : 0.8659\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from nltk.translate.bleu_score import (\n",
    "    sentence_bleu,\n",
    "    SmoothingFunction,\n",
    ")  # BLEU score computation\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bertscore\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Data Loading and Preprocessing\n",
    "df = pd.read_csv(\n",
    "    r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Data\\Test_data.csv\"\n",
    ")  ## CHANGE this path with you processed test.csv data (Upon which we need to apply pipeline)\n",
    "df = df[[\"Social Media Post\", \"Normalized Claim\"]].dropna().drop_duplicates()\n",
    "df = df[\n",
    "    (df[\"Social Media Post\"].str.strip() != \"\")\n",
    "    & (df[\"Normalized Claim\"].str.strip() != \"\")\n",
    "]\n",
    "\n",
    "\n",
    "# Load T5 tokenizer and pretrained saved model\n",
    "model_path = r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Model\\T5\\t5_clan\"  # CHange the Model path also (with pretrained saved checkpoints)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Move model to device (GPU is preferred)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Inference function\n",
    "def generate_prediction(text):\n",
    "    input_text = \"normalize: \" + text\n",
    "    encodings = tokenizer(\n",
    "        input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256\n",
    "    )\n",
    "    input_ids = encodings[\"input_ids\"].to(device)\n",
    "    attn_mask = encodings[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=input_ids, attention_mask=attn_mask, max_length=128, num_beams=4\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Generate predictions for the test set\n",
    "predictions = []\n",
    "for text in tqdm(df[\"Social Media Post\"]):\n",
    "    pred = generate_prediction(text)\n",
    "    predictions.append(pred)\n",
    "\n",
    "df[\"Predicted Claim\"] = predictions\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "references = df[\"Normalized Claim\"].tolist()\n",
    "preds = df[\"Predicted Claim\"].tolist()\n",
    "\n",
    "# BLEU-4\n",
    "bleu_scores = [\n",
    "    sentence_bleu(\n",
    "        [ref.split()], pred.split(), smoothing_function=SmoothingFunction().method1\n",
    "    )\n",
    "    for ref, pred in zip(references, preds)\n",
    "]\n",
    "bleu4 = round(sum(bleu_scores) / len(bleu_scores), 4)\n",
    "\n",
    "# ROUGE-L\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "rouge_scores = [\n",
    "    rouge.score(ref, pred)[\"rougeL\"].fmeasure for ref, pred in zip(references, preds)\n",
    "]\n",
    "rougeL = round(sum(rouge_scores) / len(rouge_scores), 4)\n",
    "\n",
    "# BERTScore\n",
    "_, _, f1 = bertscore(preds, references, lang=\"en\", verbose=False)\n",
    "bert_score = round(f1.mean().item(), 4)\n",
    "\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "print(\"BLEU-4    :\", bleu4)\n",
    "print(\"ROUGE-L   :\", rougeL)\n",
    "print(\"BERTScore :\", bert_score)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df.to_csv(r\"E:\\MTechCSE\\Study\\Sem2\\NLP\\Assignment\\Assignment_3\\Final\\Data\\T5_Test_Predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9f9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7084456,
     "sourceId": 11326009,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 296453,
     "modelInstanceId": 275558,
     "sourceId": 328392,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venvClaimNormalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
